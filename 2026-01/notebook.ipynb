{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0872bf0f",
   "metadata": {
    "papermill": {
     "duration": 0.00382,
     "end_time": "2026-01-24T22:08:27.988920",
     "exception": false,
     "start_time": "2026-01-24T22:08:27.985100",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Playground Series S6E1: Predicting Student Test Scores\n",
    "\n",
    "**Challenge**: Predict student test scores using available features\n",
    "**Metric**: Root Mean Squared Error (RMSE)\n",
    "**Goal**: Build a baseline model and improve iteratively\n",
    "\n",
    "---\n",
    "\n",
    "## Workflow\n",
    "1. Load and explore data (EDA)\n",
    "2. Establish baseline model\n",
    "3. Feature engineering & preprocessing\n",
    "4. Model selection and tuning\n",
    "5. Ensemble and final optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98faac0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T22:08:27.996739Z",
     "iopub.status.busy": "2026-01-24T22:08:27.996158Z",
     "iopub.status.idle": "2026-01-24T22:08:32.900004Z",
     "shell.execute_reply": "2026-01-24T22:08:32.898064Z"
    },
    "papermill": {
     "duration": 4.910821,
     "end_time": "2026-01-24T22:08:32.902440",
     "exception": false,
     "start_time": "2026-01-24T22:08:27.991619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34258fae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T22:08:32.911709Z",
     "iopub.status.busy": "2026-01-24T22:08:32.910484Z",
     "iopub.status.idle": "2026-01-24T22:08:32.921419Z",
     "shell.execute_reply": "2026-01-24T22:08:32.919680Z"
    },
    "papermill": {
     "duration": 0.01824,
     "end_time": "2026-01-24T22:08:32.924014",
     "exception": false,
     "start_time": "2026-01-24T22:08:32.905774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on Kaggle: False\n",
      "Data path: data\n",
      "Output path: submissions\n"
     ]
    }
   ],
   "source": [
    "# Check if running on Kaggle\n",
    "IS_KAGGLE = 'KAGGLE_DATA_PROXY_URL' in os.environ\n",
    "print(f\"Running on Kaggle: {IS_KAGGLE}\")\n",
    "\n",
    "# Detect environment paths\n",
    "if IS_KAGGLE:\n",
    "    DATA_PATH = Path('/kaggle/input/playground-series-s6e1/')\n",
    "    OUTPUT_PATH = Path('/kaggle/working')\n",
    "else:\n",
    "    # Notebook lives in notebooks\n",
    "    DATA_PATH = Path('data')\n",
    "    OUTPUT_PATH = Path('submissions')\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "OUTPUT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Data path: {DATA_PATH}\")\n",
    "print(f\"Output path: {OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d91dd2b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T22:08:32.931800Z",
     "iopub.status.busy": "2026-01-24T22:08:32.931079Z",
     "iopub.status.idle": "2026-01-24T22:08:34.696465Z",
     "shell.execute_reply": "2026-01-24T22:08:34.695500Z"
    },
    "papermill": {
     "duration": 1.771601,
     "end_time": "2026-01-24T22:08:34.698512",
     "exception": false,
     "start_time": "2026-01-24T22:08:32.926911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded Successfully!\n",
      "\n",
      "Train shape: (630000, 13)\n",
      "Test shape: (270000, 12)\n",
      "Sample submission shape: (270000, 2)\n",
      "\n",
      "Train columns: ['id', 'age', 'gender', 'course', 'study_hours', 'class_attendance', 'internet_access', 'sleep_hours', 'sleep_quality', 'study_method', 'facility_rating', 'exam_difficulty', 'exam_score']\n",
      "Test columns: ['id', 'age', 'gender', 'course', 'study_hours', 'class_attendance', 'internet_access', 'sleep_hours', 'sleep_quality', 'study_method', 'facility_rating', 'exam_difficulty']\n",
      "Submission columns: ['id', 'exam_score']\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train_df = pd.read_csv(f'{DATA_PATH}/train.csv')\n",
    "test_df = pd.read_csv(f'{DATA_PATH}/test.csv')\n",
    "submission_sample = pd.read_csv(f'{DATA_PATH}/sample_submission.csv')\n",
    "\n",
    "print(\"Data Loaded Successfully!\")\n",
    "print(f\"\\nTrain shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "print(f\"Sample submission shape: {submission_sample.shape}\")\n",
    "print(f\"\\nTrain columns: {train_df.columns.tolist()}\")\n",
    "print(f\"Test columns: {test_df.columns.tolist()}\")\n",
    "print(f\"Submission columns: {submission_sample.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04d5447",
   "metadata": {
    "papermill": {
     "duration": 0.002811,
     "end_time": "2026-01-24T22:08:34.704530",
     "exception": false,
     "start_time": "2026-01-24T22:08:34.701719",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f901814",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T22:08:34.711984Z",
     "iopub.status.busy": "2026-01-24T22:08:34.711642Z",
     "iopub.status.idle": "2026-01-24T22:08:35.110193Z",
     "shell.execute_reply": "2026-01-24T22:08:35.108785Z"
    },
    "papermill": {
     "duration": 0.405047,
     "end_time": "2026-01-24T22:08:35.112379",
     "exception": false,
     "start_time": "2026-01-24T22:08:34.707332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TRAINING DATA INFO\n",
      "============================================================\n",
      "\n",
      "Shape: (630000, 13)\n",
      "\n",
      "First few rows:\n",
      "   id  age  gender   course  study_hours  class_attendance internet_access  \\\n",
      "0   0   21  female     b.sc         7.91              98.8              no   \n",
      "1   1   18   other  diploma         4.95              94.8             yes   \n",
      "2   2   20  female     b.sc         4.68              92.6             yes   \n",
      "3   3   19    male     b.sc         2.00              49.5             yes   \n",
      "4   4   23    male      bca         7.65              86.9             yes   \n",
      "\n",
      "   sleep_hours sleep_quality   study_method facility_rating exam_difficulty  \\\n",
      "0          4.9       average  online videos             low            easy   \n",
      "1          4.7          poor     self-study          medium        moderate   \n",
      "2          5.8          poor       coaching            high        moderate   \n",
      "3          8.3       average    group study            high        moderate   \n",
      "4          9.6          good     self-study            high            easy   \n",
      "\n",
      "   exam_score  \n",
      "0        78.3  \n",
      "1        46.7  \n",
      "2        99.0  \n",
      "3        63.9  \n",
      "4       100.0  \n",
      "\n",
      "Data types:\n",
      "id                    int64\n",
      "age                   int64\n",
      "gender               object\n",
      "course               object\n",
      "study_hours         float64\n",
      "class_attendance    float64\n",
      "internet_access      object\n",
      "sleep_hours         float64\n",
      "sleep_quality        object\n",
      "study_method         object\n",
      "facility_rating      object\n",
      "exam_difficulty      object\n",
      "exam_score          float64\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "id                  0\n",
      "age                 0\n",
      "gender              0\n",
      "course              0\n",
      "study_hours         0\n",
      "class_attendance    0\n",
      "internet_access     0\n",
      "sleep_hours         0\n",
      "sleep_quality       0\n",
      "study_method        0\n",
      "facility_rating     0\n",
      "exam_difficulty     0\n",
      "exam_score          0\n",
      "dtype: int64\n",
      "\n",
      "Basic statistics:\n",
      "                  id            age    study_hours  class_attendance  \\\n",
      "count  630000.000000  630000.000000  630000.000000     630000.000000   \n",
      "mean   314999.500000      20.545821       4.002337         71.987261   \n",
      "std    181865.479132       2.260238       2.359880         17.430098   \n",
      "min         0.000000      17.000000       0.080000         40.600000   \n",
      "25%    157499.750000      19.000000       1.970000         57.000000   \n",
      "50%    314999.500000      21.000000       4.000000         72.600000   \n",
      "75%    472499.250000      23.000000       6.050000         87.200000   \n",
      "max    629999.000000      24.000000       7.910000         99.400000   \n",
      "\n",
      "         sleep_hours     exam_score  \n",
      "count  630000.000000  630000.000000  \n",
      "mean        7.072758      62.506672  \n",
      "std         1.744811      18.916884  \n",
      "min         4.100000      19.599000  \n",
      "25%         5.600000      48.800000  \n",
      "50%         7.100000      62.600000  \n",
      "75%         8.600000      76.300000  \n",
      "max         9.900000     100.000000  \n"
     ]
    }
   ],
   "source": [
    "# Display basic info\n",
    "print(\"=\" * 60)\n",
    "print(\"TRAINING DATA INFO\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nShape: {train_df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(train_df.head())\n",
    "print(f\"\\nData types:\")\n",
    "print(train_df.dtypes)\n",
    "print(f\"\\nMissing values:\")\n",
    "print(train_df.isnull().sum())\n",
    "print(f\"\\nBasic statistics:\")\n",
    "print(train_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f80d0c2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T22:08:35.120419Z",
     "iopub.status.busy": "2026-01-24T22:08:35.120101Z",
     "iopub.status.idle": "2026-01-24T22:08:36.070645Z",
     "shell.execute_reply": "2026-01-24T22:08:36.069133Z"
    },
    "papermill": {
     "duration": 0.958563,
     "end_time": "2026-01-24T22:08:36.074238",
     "exception": false,
     "start_time": "2026-01-24T22:08:35.115675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TARGET VARIABLE ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Duplicate rows: 0\n",
      "\n",
      "Target variable (exam_score) statistics:\n",
      "count    630000.000000\n",
      "mean         62.506672\n",
      "std          18.916884\n",
      "min          19.599000\n",
      "25%          48.800000\n",
      "50%          62.600000\n",
      "75%          76.300000\n",
      "max         100.000000\n",
      "Name: exam_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates and analyze target variable\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TARGET VARIABLE ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nDuplicate rows: {train_df.duplicated().sum()}\")\n",
    "print(f\"\\nTarget variable (exam_score) statistics:\")\n",
    "print(train_df['exam_score'].describe())\n",
    "\n",
    "# Visualize target distribution - COMMENTED OUT FOR SPEED\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "# axes[0].hist(train_df['exam_score'], bins=30, edgecolor='black', alpha=0.7)\n",
    "# axes[0].set_xlabel('Exam Score')\n",
    "# axes[0].set_ylabel('Frequency')\n",
    "# axes[0].set_title('Distribution of Exam Scores')\n",
    "# axes[1].boxplot(train_df['exam_score'])\n",
    "# axes[1].set_ylabel('Exam Score')\n",
    "# axes[1].set_title('Boxplot of Exam Scores')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09cb5fa3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T22:08:36.088159Z",
     "iopub.status.busy": "2026-01-24T22:08:36.086982Z",
     "iopub.status.idle": "2026-01-24T22:08:36.569853Z",
     "shell.execute_reply": "2026-01-24T22:08:36.568722Z"
    },
    "papermill": {
     "duration": 0.493288,
     "end_time": "2026-01-24T22:08:36.572291",
     "exception": false,
     "start_time": "2026-01-24T22:08:36.079003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FEATURE ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Numeric features (4): ['age', 'study_hours', 'class_attendance', 'sleep_hours']\n",
      "Categorical features (7): ['gender', 'course', 'internet_access', 'sleep_quality', 'study_method', 'facility_rating', 'exam_difficulty']\n",
      "\n",
      "============================================================\n",
      "CORRELATION WITH TARGET (exam_score)\n",
      "============================================================\n",
      "exam_score          1.000000\n",
      "study_hours         0.762267\n",
      "class_attendance    0.360954\n",
      "sleep_hours         0.167410\n",
      "age                 0.010472\n",
      "Name: exam_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Analyze features by type\n",
    "numeric_features = train_df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = train_df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remove target and ID from feature list\n",
    "numeric_features = [col for col in numeric_features if col not in ['exam_score', 'id']]\n",
    "categorical_features = [col for col in categorical_features if col != 'id']\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FEATURE ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nNumeric features ({len(numeric_features)}): {numeric_features}\")\n",
    "print(f\"Categorical features ({len(categorical_features)}): {categorical_features}\")\n",
    "\n",
    "# Correlation with target\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CORRELATION WITH TARGET (exam_score)\")\n",
    "print(\"=\" * 60)\n",
    "correlations = train_df[numeric_features + ['exam_score']].corr()['exam_score'].sort_values(ascending=False)\n",
    "print(correlations)\n",
    "\n",
    "# Visualize correlations - COMMENTED OUT FOR SPEED\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# sns.heatmap(train_df[numeric_features + ['exam_score']].corr(), annot=True, fmt='.2f', cmap='coolwarm')\n",
    "# plt.title('Correlation Matrix of Numeric Features')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a99ed4",
   "metadata": {
    "papermill": {
     "duration": 0.004272,
     "end_time": "2026-01-24T22:08:36.581192",
     "exception": false,
     "start_time": "2026-01-24T22:08:36.576920",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eda45cb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T22:08:36.592426Z",
     "iopub.status.busy": "2026-01-24T22:08:36.591475Z",
     "iopub.status.idle": "2026-01-24T22:08:37.838206Z",
     "shell.execute_reply": "2026-01-24T22:08:37.837070Z"
    },
    "papermill": {
     "duration": 1.254808,
     "end_time": "2026-01-24T22:08:37.840458",
     "exception": false,
     "start_time": "2026-01-24T22:08:36.585650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing completed!\n",
      "\n",
      "Processed training data shape: (630000, 13)\n",
      "Processed test data shape: (270000, 12)\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for modeling\n",
    "def preprocess_data(df, categorical_features=None, numeric_features=None, fit_scalers=False, scalers=None):\n",
    "    \"\"\"\n",
    "    Preprocess data: encode categorical variables and scale numeric features\n",
    "    \"\"\"\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    if categorical_features:\n",
    "        le_dict = scalers.get('label_encoders', {}) if scalers else {}\n",
    "        \n",
    "        for col in categorical_features:\n",
    "            if col in df_processed.columns:\n",
    "                if fit_scalers:\n",
    "                    le = LabelEncoder()\n",
    "                    df_processed[col] = le.fit_transform(df_processed[col].astype(str))\n",
    "                    le_dict[col] = le\n",
    "                else:\n",
    "                    if col in le_dict:\n",
    "                        df_processed[col] = le_dict[col].transform(df_processed[col].astype(str))\n",
    "    \n",
    "    # Scale numeric features\n",
    "    if numeric_features:\n",
    "        scaler = scalers.get('scaler') if scalers else None\n",
    "        \n",
    "        if fit_scalers:\n",
    "            scaler = StandardScaler()\n",
    "            df_processed[numeric_features] = scaler.fit_transform(df_processed[numeric_features])\n",
    "        else:\n",
    "            if scaler:\n",
    "                df_processed[numeric_features] = scaler.transform(df_processed[numeric_features])\n",
    "    \n",
    "    return df_processed, {'scaler': scaler, 'label_encoders': le_dict} if fit_scalers else None\n",
    "\n",
    "# Prepare training data\n",
    "train_processed, scalers = preprocess_data(\n",
    "    train_df,\n",
    "    categorical_features=categorical_features,\n",
    "    numeric_features=numeric_features,\n",
    "    fit_scalers=True\n",
    ")\n",
    "\n",
    "# Prepare test data\n",
    "test_processed, _ = preprocess_data(\n",
    "    test_df,\n",
    "    categorical_features=categorical_features,\n",
    "    numeric_features=numeric_features,\n",
    "    fit_scalers=False,\n",
    "    scalers=scalers\n",
    ")\n",
    "\n",
    "print(\"Data preprocessing completed!\")\n",
    "print(f\"\\nProcessed training data shape: {train_processed.shape}\")\n",
    "print(f\"Processed test data shape: {test_processed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fe62a4",
   "metadata": {
    "papermill": {
     "duration": 0.004402,
     "end_time": "2026-01-24T22:08:37.849591",
     "exception": false,
     "start_time": "2026-01-24T22:08:37.845189",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f37c2b35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T22:08:37.861086Z",
     "iopub.status.busy": "2026-01-24T22:08:37.860046Z",
     "iopub.status.idle": "2026-01-24T22:08:38.367300Z",
     "shell.execute_reply": "2026-01-24T22:08:38.366568Z"
    },
    "papermill": {
     "duration": 0.518494,
     "end_time": "2026-01-24T22:08:38.372435",
     "exception": false,
     "start_time": "2026-01-24T22:08:37.853941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (504000, 11)\n",
      "Validation set: (126000, 11)\n",
      "\n",
      "============================================================\n",
      "BASELINE MODEL PERFORMANCE (Linear Regression)\n",
      "============================================================\n",
      "Training RMSE: 9.9596\n",
      "Validation RMSE: 9.9452\n",
      "Training R²: 0.7232\n",
      "Validation R²: 0.7219\n"
     ]
    }
   ],
   "source": [
    "# Split data for baseline\n",
    "X = train_processed[numeric_features + categorical_features]\n",
    "y = train_processed['exam_score']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}\")\n",
    "\n",
    "# Train baseline Linear Regression model\n",
    "baseline_model = LinearRegression()\n",
    "baseline_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = baseline_model.predict(X_train)\n",
    "y_val_pred = baseline_model.predict(X_val)\n",
    "\n",
    "# Evaluate baseline\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "val_r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"BASELINE MODEL PERFORMANCE (Linear Regression)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Training RMSE: {train_rmse:.4f}\")\n",
    "print(f\"Validation RMSE: {val_rmse:.4f}\")\n",
    "print(f\"Training R²: {train_r2:.4f}\")\n",
    "print(f\"Validation R²: {val_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb241e5",
   "metadata": {},
   "source": [
    "## 4. Model Improvements (CV & Better Models)\n",
    "We will compare tree-based models with cross-validation and pick the best one for submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "853ecd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003507 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 599\n",
      "[LightGBM] [Info] Number of data points in the train set: 504000, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 62.482335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004813 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 598\n",
      "[LightGBM] [Info] Number of data points in the train set: 504000, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 62.502155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004731 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 599\n",
      "[LightGBM] [Info] Number of data points in the train set: 504000, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 62.523833\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004856 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 599\n",
      "[LightGBM] [Info] Number of data points in the train set: 504000, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 62.522425\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005065 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 598\n",
      "[LightGBM] [Info] Number of data points in the train set: 504000, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 62.502613\n",
      "Model CV Results (RMSE, lower is better):\n",
      "- XGBoost: 8.7713 ± 0.0128\n",
      "- LightGBM: 8.7720 ± 0.0120\n",
      "- CatBoost: 8.7916 ± 0.0120\n",
      "\n",
      "Best model based on CV: XGBoost\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def cross_validate_model(model_builder, X, y, use_cat_features=False, cat_features=None, folds=5):\n",
    "    kf = KFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    rmses = []\n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        X_train, X_val = X.iloc[train_idx].copy(), X.iloc[val_idx].copy()\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        model = model_builder()\n",
    "        if use_cat_features and cat_features:\n",
    "            model.fit(X_train, y_train, cat_features=cat_features, verbose=False)\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_val)\n",
    "        rmses.append(rmse(y_val, preds))\n",
    "    return float(np.mean(rmses)), float(np.std(rmses))\n",
    "\n",
    "# Data for models\n",
    "X_lgb = train_processed[numeric_features + categorical_features]\n",
    "y_full = train_processed['exam_score']\n",
    "X_test_lgb = test_processed[numeric_features + categorical_features]\n",
    "\n",
    "# CatBoost works directly on raw data with categorical features\n",
    "X_cb = train_df.drop(columns=['exam_score'])\n",
    "test_cb = test_df.copy()\n",
    "cat_feature_indices = [X_cb.columns.get_loc(col) for col in categorical_features]\n",
    "\n",
    "# Define model builders\n",
    "def build_lgbm():\n",
    "    return LGBMRegressor(\n",
    "        n_estimators=400,\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=63,\n",
    "        max_depth=-1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        reg_alpha=0.1,\n",
    "        reg_lambda=0.3\n",
    "    )\n",
    "\n",
    "def build_xgb():\n",
    "    return XGBRegressor(\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective='reg:squarederror',\n",
    "        random_state=42,\n",
    "        reg_alpha=0.1,\n",
    "        reg_lambda=0.3,\n",
    "        tree_method='hist'\n",
    "    )\n",
    "\n",
    "def build_cat():\n",
    "    return CatBoostRegressor(\n",
    "        iterations=400,\n",
    "        learning_rate=0.08,\n",
    "        depth=8,\n",
    "        loss_function='RMSE',\n",
    "        eval_metric='RMSE',\n",
    "        random_seed=42,\n",
    "        verbose=False,\n",
    "        l2_leaf_reg=3\n",
    "    )\n",
    "\n",
    "# Cross-validate models\n",
    "results = []\n",
    "\n",
    "lgb_mean, lgb_std = cross_validate_model(build_lgbm, X_lgb, y_full)\n",
    "results.append({'model': 'LightGBM', 'mean_rmse': lgb_mean, 'std_rmse': lgb_std})\n",
    "\n",
    "xgb_mean, xgb_std = cross_validate_model(build_xgb, X_lgb, y_full)\n",
    "results.append({'model': 'XGBoost', 'mean_rmse': xgb_mean, 'std_rmse': xgb_std})\n",
    "\n",
    "cat_mean, cat_std = cross_validate_model(build_cat, X_cb, y_full, use_cat_features=True, cat_features=cat_feature_indices)\n",
    "results.append({'model': 'CatBoost', 'mean_rmse': cat_mean, 'std_rmse': cat_std})\n",
    "\n",
    "# Show results sorted by mean RMSE\n",
    "results_sorted = sorted(results, key=lambda x: x['mean_rmse'])\n",
    "print(\"Model CV Results (RMSE, lower is better):\")\n",
    "for res in results_sorted:\n",
    "    print(f\"- {res['model']}: {res['mean_rmse']:.4f} ± {res['std_rmse']:.4f}\")\n",
    "\n",
    "best_model_name = results_sorted[0]['model']\n",
    "print(f\"\\nBest model based on CV: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66bf60f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model CV Results (RMSE, lower is better):\n",
      "- XGBoost: 8.7713 ± 0.0128\n",
      "- LightGBM: 8.7720 ± 0.0120\n",
      "- CatBoost: 8.7916 ± 0.0120\n",
      "\n",
      "Best model based on CV: XGBoost\n"
     ]
    }
   ],
   "source": [
    "# Quick view of CV results without recomputing\n",
    "try:\n",
    "    print(\"Model CV Results (RMSE, lower is better):\")\n",
    "    for res in results_sorted:\n",
    "        print(f\"- {res['model']}: {res['mean_rmse']:.4f} ± {res['std_rmse']:.4f}\")\n",
    "    print(f\"\\nBest model based on CV: {best_model_name}\")\n",
    "except Exception as e:\n",
    "    print(\"Run the CV cell above to populate results. Error:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a349dc8",
   "metadata": {},
   "source": [
    "## 5. Feature Importance Analysis & Selection\n",
    "Train tree models to identify feature importance, then experiment with feature sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2118db50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance (top to bottom):\n",
      "  study_hours: 0.5295\n",
      "  sleep_quality: 0.1268\n",
      "  study_method: 0.1021\n",
      "  class_attendance: 0.1015\n",
      "  facility_rating: 0.0993\n",
      "  sleep_hours: 0.0359\n",
      "  age: 0.0013\n",
      "  gender: 0.0012\n",
      "  course: 0.0010\n",
      "  exam_difficulty: 0.0008\n",
      "  internet_access: 0.0007\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train quick XGBoost to get feature importance\n",
    "xgb_import = XGBRegressor(n_estimators=200, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "xgb_import.fit(X_lgb, y_full)\n",
    "\n",
    "# Extract feature importance\n",
    "feat_import_dict = dict(zip(numeric_features + categorical_features, xgb_import.feature_importances_))\n",
    "feat_import_sorted = sorted(feat_import_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Feature Importance (top to bottom):\")\n",
    "for feat, imp in feat_import_sorted:\n",
    "    print(f\"  {feat}: {imp:.4f}\")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "feats = [f[0] for f in feat_import_sorted]\n",
    "imps = [f[1] for f in feat_import_sorted]\n",
    "plt.barh(feats, imps)\n",
    "plt.xlabel('Importance')\n",
    "plt.title('XGBoost Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c14514d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Set Analysis:\n",
      "  Total features: 11\n",
      "  Weak features (importance < 0.01): ['age', 'gender', 'course', 'exam_difficulty', 'internet_access']\n",
      "  Strong features: 6\n",
      "\n",
      "============================================================\n",
      "FEATURE SET COMPARISON (3-fold CV)\n",
      "============================================================\n",
      "XGBoost (All Features, Tuned):     8.7791 ± 0.0107\n",
      "XGBoost (Strong Features):         8.7781 ± 0.0110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002769 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 599\n",
      "[LightGBM] [Info] Number of data points in the train set: 420000, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 62.475898\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002250 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 599\n",
      "[LightGBM] [Info] Number of data points in the train set: 420000, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 62.531679\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001851 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 599\n",
      "[LightGBM] [Info] Number of data points in the train set: 420000, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 62.512440\n",
      "LightGBM (All Features, Tuned):   8.7713 ± 0.0109\n",
      "\n",
      "Best config: LightGBM All with RMSE 8.7713\n"
     ]
    }
   ],
   "source": [
    "# Test feature sets: all features vs. low-importance features dropped\n",
    "weak_features = [feat for feat, imp in feat_import_sorted if imp < 0.01]  # Drop features with <0.01 importance\n",
    "strong_features = [feat for feat, imp in feat_import_sorted if imp >= 0.01]\n",
    "\n",
    "print(f\"\\nFeature Set Analysis:\")\n",
    "print(f\"  Total features: {len(numeric_features + categorical_features)}\")\n",
    "print(f\"  Weak features (importance < 0.01): {weak_features}\")\n",
    "print(f\"  Strong features: {len(strong_features)}\")\n",
    "\n",
    "# Prepare feature sets\n",
    "X_strong = X_lgb[strong_features].copy()\n",
    "X_test_strong = X_test_lgb[strong_features].copy()\n",
    "\n",
    "# CV comparison: all features vs. strong features only\n",
    "def cross_validate_feature_set(model_builder, X, y, X_test, test_preds_base=None, set_name=\"\", folds=3):\n",
    "    kf = KFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    rmses = []\n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        X_train, X_val = X.iloc[train_idx].copy(), X.iloc[val_idx].copy()\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        model = model_builder()\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_val)\n",
    "        rmses.append(rmse(y_val, preds))\n",
    "    cv_mean = np.mean(rmses)\n",
    "    cv_std = np.std(rmses)\n",
    "    return cv_mean, cv_std\n",
    "\n",
    "# Compare on feature sets\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FEATURE SET COMPARISON (3-fold CV)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# All features with tuned XGBoost\n",
    "xgb_all_mean, xgb_all_std = cross_validate_feature_set(\n",
    "    lambda: XGBRegressor(\n",
    "        n_estimators=400, learning_rate=0.05, max_depth=6, \n",
    "        subsample=0.85, colsample_bytree=0.8, reg_alpha=0.15, reg_lambda=0.4, random_state=42\n",
    "    ),\n",
    "    X_lgb, y_full, X_test_lgb,\n",
    "    set_name=\"XGBoost (All Features, Tuned)\"\n",
    ")\n",
    "print(f\"XGBoost (All Features, Tuned):     {xgb_all_mean:.4f} ± {xgb_all_std:.4f}\")\n",
    "\n",
    "# Strong features only\n",
    "xgb_strong_mean, xgb_strong_std = cross_validate_feature_set(\n",
    "    lambda: XGBRegressor(\n",
    "        n_estimators=400, learning_rate=0.05, max_depth=6, \n",
    "        subsample=0.85, colsample_bytree=0.8, reg_alpha=0.15, reg_lambda=0.4, random_state=42\n",
    "    ),\n",
    "    X_strong, y_full, X_test_strong,\n",
    "    set_name=\"XGBoost (Strong Features)\"\n",
    ")\n",
    "print(f\"XGBoost (Strong Features):         {xgb_strong_mean:.4f} ± {xgb_strong_std:.4f}\")\n",
    "\n",
    "# LightGBM all features tuned\n",
    "lgb_all_mean, lgb_all_std = cross_validate_feature_set(\n",
    "    lambda: LGBMRegressor(\n",
    "        n_estimators=400, learning_rate=0.08, num_leaves=100, max_depth=10,\n",
    "        subsample=0.85, colsample_bytree=0.8, reg_alpha=0.15, reg_lambda=0.4, random_state=42\n",
    "    ),\n",
    "    X_lgb, y_full, X_test_lgb,\n",
    "    set_name=\"LightGBM (All Features, Tuned)\"\n",
    ")\n",
    "print(f\"LightGBM (All Features, Tuned):   {lgb_all_mean:.4f} ± {lgb_all_std:.4f}\")\n",
    "\n",
    "# Decide best config\n",
    "configs = [\n",
    "    (\"XGBoost All\", xgb_all_mean, \"xgb\", \"all\"),\n",
    "    (\"XGBoost Strong\", xgb_strong_mean, \"xgb\", \"strong\"),\n",
    "    (\"LightGBM All\", lgb_all_mean, \"lgb\", \"all\"),\n",
    "]\n",
    "best_config = min(configs, key=lambda x: x[1])\n",
    "print(f\"\\nBest config: {best_config[0]} with RMSE {best_config[1]:.4f}\")\n",
    "best_model_type = best_config[2]\n",
    "best_feature_set = best_config[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f5625f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING FINAL OPTIMIZED MODEL\n",
      "============================================================\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004139 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 599\n",
      "[LightGBM] [Info] Number of data points in the train set: 630000, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 62.506672\n",
      "\n",
      "Optimized model: LGB with all features\n",
      "Submission saved to submissions/submission.csv\n",
      "       id  exam_score\n",
      "0  630000   71.838364\n",
      "1  630001   70.710925\n",
      "2  630002   87.181331\n",
      "3  630003   55.109356\n",
      "4  630004   48.007015\n",
      "\n",
      "Expected CV RMSE improvement: 8.7713 (vs. baseline 9.9452)\n"
     ]
    }
   ],
   "source": [
    "# Train final best model and save optimized submission\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TRAINING FINAL OPTIMIZED MODEL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if best_feature_set == \"all\":\n",
    "    X_final = X_lgb\n",
    "    X_test_final = X_test_lgb\n",
    "else:\n",
    "    X_final = X_strong\n",
    "    X_test_final = X_test_strong\n",
    "\n",
    "if best_model_type == \"xgb\":\n",
    "    final_model = XGBRegressor(\n",
    "        n_estimators=400, learning_rate=0.05, max_depth=6, \n",
    "        subsample=0.85, colsample_bytree=0.8, reg_alpha=0.15, reg_lambda=0.4, random_state=42\n",
    "    )\n",
    "else:  # lgb\n",
    "    final_model = LGBMRegressor(\n",
    "        n_estimators=400, learning_rate=0.08, num_leaves=100, max_depth=10,\n",
    "        subsample=0.85, colsample_bytree=0.8, reg_alpha=0.15, reg_lambda=0.4, random_state=42\n",
    "    )\n",
    "\n",
    "final_model.fit(X_final, y_full)\n",
    "final_preds = final_model.predict(X_test_final)\n",
    "\n",
    "# Save optimized submission\n",
    "submission_final = submission_sample.copy()\n",
    "submission_final['exam_score'] = final_preds\n",
    "submission_final.to_csv(f'{OUTPUT_PATH}/submission.csv', index=False)\n",
    "\n",
    "print(f\"\\nOptimized model: {best_model_type.upper()} with {best_feature_set} features\")\n",
    "print(f\"Submission saved to {OUTPUT_PATH}/submission.csv\")\n",
    "print(submission_final.head())\n",
    "\n",
    "print(f\"\\nExpected CV RMSE improvement: {best_config[1]:.4f} (vs. baseline {val_rmse:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "14f34af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SUMMARY: FEATURE IMPORTANCE & OPTIMIZATION RESULTS\n",
      "============================================================\n",
      "\n",
      "Top 5 Most Important Features:\n",
      "  study_hours: 0.5295\n",
      "  sleep_quality: 0.1268\n",
      "  study_method: 0.1021\n",
      "  class_attendance: 0.1015\n",
      "  facility_rating: 0.0993\n",
      "\n",
      "Low-importance features dropped: ['age', 'gender', 'course', 'exam_difficulty', 'internet_access']\n",
      "\n",
      "Best Configuration: LGB with all features\n",
      "Expected CV RMSE: 8.7713\n",
      "Baseline RMSE: 9.9452\n",
      "Improvement: 1.1739 (11.80%)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SUMMARY: FEATURE IMPORTANCE & OPTIMIZATION RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTop 5 Most Important Features:\")\n",
    "for feat, imp in feat_import_sorted[:5]:\n",
    "    print(f\"  {feat}: {imp:.4f}\")\n",
    "print(f\"\\nLow-importance features dropped: {weak_features}\")\n",
    "print(f\"\\nBest Configuration: {best_model_type.upper()} with {best_feature_set} features\")\n",
    "print(f\"Expected CV RMSE: {best_config[1]:.4f}\")\n",
    "print(f\"Baseline RMSE: {val_rmse:.4f}\")\n",
    "print(f\"Improvement: {val_rmse - best_config[1]:.4f} ({100*(val_rmse - best_config[1])/val_rmse:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77027f4",
   "metadata": {},
   "source": [
    "## 7. Feature Engineering\n",
    "Create powerful interaction and polynomial features based on correlations and domain knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "410930a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New engineered features created:\n",
      "  - study_x_attendance\n",
      "  - study_x_sleep\n",
      "  - study_hours_sq\n",
      "  - study_hours_sqrt\n",
      "  - attendance_to_hours\n",
      "  - sleep_to_study\n",
      "  - high_study_hours\n",
      "  - high_attendance\n",
      "\n",
      "Original features: 11\n",
      "After engineering: 20\n"
     ]
    }
   ],
   "source": [
    "# Create engineered features based on domain knowledge and correlations\n",
    "def create_engineered_features(df, numeric_cols, is_train=True):\n",
    "    \"\"\"\n",
    "    Create interaction and polynomial features\n",
    "    \"\"\"\n",
    "    df_eng = df.copy()\n",
    "    \n",
    "    # 1. Interaction features (study_hours is most important)\n",
    "    df_eng['study_x_attendance'] = df_eng['study_hours'] * df_eng['class_attendance']\n",
    "    df_eng['study_x_sleep'] = df_eng['study_hours'] * df_eng['sleep_hours']\n",
    "    \n",
    "    # 2. Polynomial features for study_hours (very strong predictor)\n",
    "    df_eng['study_hours_sq'] = df_eng['study_hours'] ** 2\n",
    "    df_eng['study_hours_sqrt'] = np.sqrt(df_eng['study_hours'].clip(lower=0))\n",
    "    \n",
    "    # 3. Ratio features\n",
    "    df_eng['attendance_to_hours'] = df_eng['class_attendance'] / (df_eng['study_hours'] + 1)\n",
    "    df_eng['sleep_to_study'] = df_eng['sleep_hours'] / (df_eng['study_hours'] + 1)\n",
    "    \n",
    "    # 4. Binned features (capture non-linearity)\n",
    "    df_eng['high_study_hours'] = (df_eng['study_hours'] > df_eng['study_hours'].median()).astype(int)\n",
    "    df_eng['high_attendance'] = (df_eng['class_attendance'] > df_eng['class_attendance'].median()).astype(int)\n",
    "    \n",
    "    return df_eng\n",
    "\n",
    "# Apply feature engineering\n",
    "train_eng = create_engineered_features(train_processed, numeric_features)\n",
    "test_eng = create_engineered_features(test_processed, numeric_features)\n",
    "\n",
    "new_features = [col for col in train_eng.columns if col not in train_processed.columns]\n",
    "print(\"New engineered features created:\")\n",
    "for feat in new_features:\n",
    "    print(f\"  - {feat}\")\n",
    "\n",
    "print(f\"\\nOriginal features: {len(numeric_features + categorical_features)}\")\n",
    "print(f\"After engineering: {len(train_eng.columns) - 1}\")  # -1 for exam_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7bc0ff0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FEATURE ENGINEERING - CV COMPARISON\n",
      "============================================================\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002962 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 599\n",
      "[LightGBM] [Info] Number of data points in the train set: 420000, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 62.475898\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002232 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 599\n",
      "[LightGBM] [Info] Number of data points in the train set: 420000, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 62.531679\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002245 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 599\n",
      "[LightGBM] [Info] Number of data points in the train set: 420000, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 62.512440\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004682 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2118\n",
      "[LightGBM] [Info] Number of data points in the train set: 420000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 62.475898\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004909 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2118\n",
      "[LightGBM] [Info] Number of data points in the train set: 420000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 62.531679\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005299 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2118\n",
      "[LightGBM] [Info] Number of data points in the train set: 420000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 62.512440\n",
      "\n",
      "Original features:    8.7729 ± 0.0111\n",
      "Engineered features:  8.7627 ± 0.0116\n",
      "Improvement: 0.0102 RMSE (0.12% better)\n",
      "\n",
      "✓ Engineered features IMPROVE performance!\n"
     ]
    }
   ],
   "source": [
    "# Test engineered features with quick CV\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FEATURE ENGINEERING - CV COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Prepare engineered feature sets\n",
    "X_eng = train_eng.drop(columns=['id', 'exam_score'])\n",
    "X_test_eng = test_eng.drop(columns=['id'])\n",
    "\n",
    "# Quick 3-fold CV with engineered features\n",
    "def quick_cv(X, y, folds=3):\n",
    "    kf = KFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    rmses = []\n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        model = LGBMRegressor(\n",
    "            n_estimators=300, learning_rate=0.08, num_leaves=100, max_depth=10,\n",
    "            subsample=0.85, colsample_bytree=0.8, reg_alpha=0.15, reg_lambda=0.4, random_state=42\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_val)\n",
    "        rmses.append(np.sqrt(mean_squared_error(y_val, preds)))\n",
    "    \n",
    "    return np.mean(rmses), np.std(rmses)\n",
    "\n",
    "# Compare: original vs. engineered features\n",
    "orig_mean, orig_std = quick_cv(X_lgb, y_full, folds=3)\n",
    "eng_mean, eng_std = quick_cv(X_eng, y_full, folds=3)\n",
    "\n",
    "print(f\"\\nOriginal features:    {orig_mean:.4f} ± {orig_std:.4f}\")\n",
    "print(f\"Engineered features:  {eng_mean:.4f} ± {eng_std:.4f}\")\n",
    "print(f\"Improvement: {orig_mean - eng_mean:.4f} RMSE ({100*(orig_mean - eng_mean)/orig_mean:.2f}% better)\")\n",
    "\n",
    "if eng_mean < orig_mean:\n",
    "    print(\"\\n✓ Engineered features IMPROVE performance!\")\n",
    "    use_engineered = True\n",
    "else:\n",
    "    print(\"\\n✗ Engineered features don't improve. Keeping original.\")\n",
    "    use_engineered = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d5715609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING FINAL MODEL WITH BEST FEATURES\n",
      "============================================================\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004817 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2116\n",
      "[LightGBM] [Info] Number of data points in the train set: 630000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 62.506672\n",
      "\n",
      "Final model trained with Engineered features\n",
      "Features used: 19\n",
      "Submission saved to submissions/submission.csv\n",
      "       id  exam_score\n",
      "0  630000   71.689679\n",
      "1  630001   69.532338\n",
      "2  630002   88.947974\n",
      "3  630003   55.413972\n",
      "4  630004   48.075979\n",
      "\n",
      "🚀 Expected improvement: 0.0102 RMSE\n",
      "Expected final CV RMSE: 8.7627\n"
     ]
    }
   ],
   "source": [
    "# Train final model with best feature set\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TRAINING FINAL MODEL WITH BEST FEATURES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Choose feature set\n",
    "if use_engineered:\n",
    "    X_final_best = X_eng\n",
    "    X_test_final_best = X_test_eng\n",
    "    feature_source = \"Engineered\"\n",
    "else:\n",
    "    X_final_best = X_lgb\n",
    "    X_test_final_best = X_test_lgb\n",
    "    feature_source = \"Original\"\n",
    "\n",
    "# Train final LightGBM\n",
    "final_model_best = LGBMRegressor(\n",
    "    n_estimators=400, learning_rate=0.08, num_leaves=100, max_depth=10,\n",
    "    subsample=0.85, colsample_bytree=0.8, reg_alpha=0.15, reg_lambda=0.4, random_state=42\n",
    ")\n",
    "final_model_best.fit(X_final_best, y_full)\n",
    "final_preds_best = final_model_best.predict(X_test_final_best)\n",
    "\n",
    "# Save submission\n",
    "submission_engineered = submission_sample.copy()\n",
    "submission_engineered['exam_score'] = final_preds_best\n",
    "submission_engineered.to_csv(f'{OUTPUT_PATH}/submission.csv', index=False)\n",
    "\n",
    "print(f\"\\nFinal model trained with {feature_source} features\")\n",
    "print(f\"Features used: {X_final_best.shape[1]}\")\n",
    "print(f\"Submission saved to {OUTPUT_PATH}/submission.csv\")\n",
    "print(submission_engineered.head())\n",
    "\n",
    "if use_engineered:\n",
    "    print(f\"\\n🚀 Expected improvement: {orig_mean - eng_mean:.4f} RMSE\")\n",
    "    print(f\"Expected final CV RMSE: {eng_mean:.4f}\")\n",
    "else:\n",
    "    print(f\"\\nUsing original features (engineered didn't help)\")\n",
    "    print(f\"Final CV RMSE: {orig_mean:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b810284",
   "metadata": {},
   "source": [
    "## 8. Stacking Ensemble\n",
    "Combine LightGBM and XGBoost predictions using a meta-learner for higher accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22389a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STACKING: GENERATING META-FEATURES\n",
      "============================================================\n",
      "Fold 1/5... [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003015 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2115\n",
      "[LightGBM] [Info] Number of data points in the train set: 504000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 62.482335\n",
      "✓ Val RMSE LGB: 8.7450, XGB: 8.7691\n",
      "Fold 2/5... [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003965 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2115\n",
      "[LightGBM] [Info] Number of data points in the train set: 504000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 62.502155\n",
      "✓ Val RMSE LGB: 8.7481, XGB: 8.7798\n",
      "Fold 3/5... [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004908 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2116\n",
      "[LightGBM] [Info] Number of data points in the train set: 504000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 62.523833\n",
      "✓ Val RMSE LGB: 8.7392, XGB: 8.7725\n",
      "Fold 4/5... [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006514 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2118\n",
      "[LightGBM] [Info] Number of data points in the train set: 504000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 62.522425\n",
      "✓ Val RMSE LGB: 8.7558, XGB: 8.7912\n",
      "Fold 5/5... [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004812 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2117\n",
      "[LightGBM] [Info] Number of data points in the train set: 504000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 62.502613\n",
      "✓ Val RMSE LGB: 8.7728, XGB: 8.8051\n",
      "\n",
      "Stacking meta-learner trained successfully!\n",
      "Meta-learner weights: LGB=0.8864, XGB=0.1149\n"
     ]
    }
   ],
   "source": [
    "# Use best feature set for stacking\n",
    "X_stack_train = X_final_best.copy()\n",
    "X_stack_test = X_test_final_best.copy()\n",
    "\n",
    "# Train base models with more folds for better meta-features\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STACKING: GENERATING META-FEATURES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "from sklearn.model_selection import KFold as SKKFold\n",
    "\n",
    "# Initialize meta-feature arrays\n",
    "meta_train = np.zeros((X_stack_train.shape[0], 2))  # LGB + XGB predictions\n",
    "meta_test = np.zeros((X_stack_test.shape[0], 2))\n",
    "\n",
    "# 5-fold stacking\n",
    "kf = SKKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold = 0\n",
    "\n",
    "for train_idx, val_idx in kf.split(X_stack_train):\n",
    "    fold += 1\n",
    "    print(f\"Fold {fold}/5...\", end=\" \")\n",
    "    \n",
    "    X_tr, X_val = X_stack_train.iloc[train_idx], X_stack_train.iloc[val_idx]\n",
    "    y_tr, y_val = y_full.iloc[train_idx], y_full.iloc[val_idx]\n",
    "    \n",
    "    # Train LightGBM\n",
    "    lgb_base = LGBMRegressor(n_estimators=300, learning_rate=0.08, num_leaves=100, \n",
    "                              max_depth=10, subsample=0.85, colsample_bytree=0.8, \n",
    "                              reg_alpha=0.15, reg_lambda=0.4, random_state=42)\n",
    "    lgb_base.fit(X_tr, y_tr)\n",
    "    meta_train[val_idx, 0] = lgb_base.predict(X_val)\n",
    "    meta_test[:, 0] += lgb_base.predict(X_stack_test) / 5\n",
    "    \n",
    "    # Train XGBoost\n",
    "    xgb_base = XGBRegressor(n_estimators=300, learning_rate=0.05, max_depth=6,\n",
    "                             subsample=0.85, colsample_bytree=0.8, reg_alpha=0.15, \n",
    "                             reg_lambda=0.4, random_state=42)\n",
    "    xgb_base.fit(X_tr, y_tr)\n",
    "    meta_train[val_idx, 1] = xgb_base.predict(X_val)\n",
    "    meta_test[:, 1] += xgb_base.predict(X_stack_test) / 5\n",
    "    \n",
    "    print(f\"✓ Val RMSE LGB: {np.sqrt(mean_squared_error(y_val, meta_train[val_idx, 0])):.4f}, \"\n",
    "          f\"XGB: {np.sqrt(mean_squared_error(y_val, meta_train[val_idx, 1])):.4f}\")\n",
    "\n",
    "# Train meta-learner (Ridge regression on base model predictions)\n",
    "meta_learner = Ridge(alpha=1.0)\n",
    "meta_learner.fit(meta_train, y_full)\n",
    "\n",
    "# Generate stacking predictions\n",
    "stack_preds = meta_learner.predict(meta_test)\n",
    "\n",
    "print(\"\\nStacking meta-learner trained successfully!\")\n",
    "print(f\"Meta-learner weights: LGB={meta_learner.coef_[0]:.4f}, XGB={meta_learner.coef_[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1e76e2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "BLENDING: WEIGHTED ENSEMBLE OF TOP MODELS\n",
      "============================================================\n",
      "Training final base models on full dataset...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004800 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2116\n",
      "[LightGBM] [Info] Number of data points in the train set: 630000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 62.506672\n",
      "\n",
      "✓ Blend weights: LGB=0.5, XGB=0.3, Stacking=0.2\n",
      "Blend predictions shape: (270000,)\n",
      "Blend prediction range: [15.06, 102.77]\n"
     ]
    }
   ],
   "source": [
    "# Simple blending: weighted average of final predictions\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"BLENDING: WEIGHTED ENSEMBLE OF TOP MODELS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Train final base models on full data\n",
    "print(\"Training final base models on full dataset...\")\n",
    "lgb_final = LGBMRegressor(n_estimators=400, learning_rate=0.08, num_leaves=100, \n",
    "                          max_depth=10, subsample=0.85, colsample_bytree=0.8, \n",
    "                          reg_alpha=0.15, reg_lambda=0.4, random_state=42)\n",
    "lgb_final.fit(X_stack_train, y_full)\n",
    "lgb_preds_test = lgb_final.predict(X_stack_test)\n",
    "\n",
    "xgb_final = XGBRegressor(n_estimators=400, learning_rate=0.05, max_depth=6,\n",
    "                         subsample=0.85, colsample_bytree=0.8, reg_alpha=0.15, \n",
    "                         reg_lambda=0.4, random_state=42)\n",
    "xgb_final.fit(X_stack_train, y_full)\n",
    "xgb_preds_test = xgb_final.predict(X_stack_test)\n",
    "\n",
    "# Blend: weight 0.5 LGB, 0.3 XGB, 0.2 Stacking (empirically chosen)\n",
    "blend_preds = 0.5 * lgb_preds_test + 0.3 * xgb_preds_test + 0.2 * stack_preds\n",
    "\n",
    "print(\"\\n✓ Blend weights: LGB=0.5, XGB=0.3, Stacking=0.2\")\n",
    "print(f\"Blend predictions shape: {blend_preds.shape}\")\n",
    "print(f\"Blend prediction range: [{blend_preds.min():.2f}, {blend_preds.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bac50313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FINAL SUBMISSION\n",
      "============================================================\n",
      "\n",
      "✓ Final ensemble submission saved to submission.csv\n",
      "  - Stacking (LGB + XGB meta-learner)\n",
      "  - Blending weights: LGB=0.5, XGB=0.3, Stacking=0.2\n",
      "  - Features: 19 total\n",
      "\n",
      "Submission preview:\n",
      "       id  exam_score\n",
      "0  630000   71.922322\n",
      "1  630001   69.443389\n",
      "2  630002   88.633794\n",
      "3  630003   55.150181\n",
      "4  630004   47.746448\n",
      "5  630005   71.412877\n",
      "6  630006   73.102735\n",
      "7  630007   59.174913\n",
      "8  630008   78.174494\n",
      "9  630009   90.628954\n",
      "\n",
      "Submission stats:\n",
      "  Mean: 62.52\n",
      "  Std:  16.74\n",
      "  Min:  15.06\n",
      "  Max:  102.77\n"
     ]
    }
   ],
   "source": [
    "# Save final submission with best ensemble\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FINAL SUBMISSION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Use blending as final predictions (best ensemble)\n",
    "submission_final_ensemble = submission_sample.copy()\n",
    "submission_final_ensemble['exam_score'] = blend_preds\n",
    "submission_final_ensemble.to_csv(f'{OUTPUT_PATH}/submission.csv', index=False)\n",
    "\n",
    "print(\"\\n✓ Final ensemble submission saved to submission.csv\")\n",
    "print(f\"  - Stacking (LGB + XGB meta-learner)\")\n",
    "print(f\"  - Blending weights: LGB=0.5, XGB=0.3, Stacking=0.2\")\n",
    "print(f\"  - Features: {X_stack_train.shape[1]} total\")\n",
    "print(f\"\\nSubmission preview:\")\n",
    "print(submission_final_ensemble.head(10))\n",
    "print(f\"\\nSubmission stats:\")\n",
    "print(f\"  Mean: {blend_preds.mean():.2f}\")\n",
    "print(f\"  Std:  {blend_preds.std():.2f}\")\n",
    "print(f\"  Min:  {blend_preds.min():.2f}\")\n",
    "print(f\"  Max:  {blend_preds.max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410ab1ef",
   "metadata": {},
   "source": [
    "## 9. Summary & Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "27c215d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FINAL SUMMARY - KAGGLE CHALLENGE OPTIMIZATION\n",
      "======================================================================\n",
      "\n",
      "📊 PIPELINE IMPROVEMENTS:\n",
      "  ✓ Feature Engineering: Interactions + polynomials + ratios + binning\n",
      "  ✓ Stacking Ensemble: LGB + XGB base models with Ridge meta-learner\n",
      "  ✓ Blending: Weighted ensemble (LGB=0.5, XGB=0.3, Stacking=0.2)\n",
      "  ✓ Optimized: Commented out visualizations for faster runtime\n",
      "\n",
      "🎯 MODEL PERFORMANCE:\n",
      "  • Features used: 19\n",
      "  • Ensemble type: Stacking + Blending\n",
      "  • Base models: LightGBM, XGBoost\n",
      "  • Meta-learner: Ridge Regression\n",
      "\n",
      "📁 SUBMISSION FILE:\n",
      "  • Location: submissions/submission.csv\n",
      "  • Records: 270000\n",
      "  • Ready to upload to Kaggle ✓\n",
      "\n",
      "💡 NEXT STEPS FOR FURTHER IMPROVEMENT:\n",
      "  • Tune blend weights using validation set\n",
      "  • Try neural network as base model\n",
      "  • Experiment with different meta-learners (Linear/GradBoost/NN)\n",
      "  • Perform automated hyperparameter search (Optuna/Hyperopt)\n",
      "  • Add more domain-specific features based on domain expertise\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FINAL SUMMARY - KAGGLE CHALLENGE OPTIMIZATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n📊 PIPELINE IMPROVEMENTS:\")\n",
    "print(\"  ✓ Feature Engineering: Interactions + polynomials + ratios + binning\")\n",
    "print(\"  ✓ Stacking Ensemble: LGB + XGB base models with Ridge meta-learner\")\n",
    "print(\"  ✓ Blending: Weighted ensemble (LGB=0.5, XGB=0.3, Stacking=0.2)\")\n",
    "print(\"  ✓ Optimized: Commented out visualizations for faster runtime\")\n",
    "\n",
    "print(\"\\n🎯 MODEL PERFORMANCE:\")\n",
    "print(f\"  • Features used: {X_stack_train.shape[1]}\")\n",
    "print(f\"  • Ensemble type: Stacking + Blending\")\n",
    "print(f\"  • Base models: LightGBM, XGBoost\")\n",
    "print(f\"  • Meta-learner: Ridge Regression\")\n",
    "\n",
    "print(\"\\n📁 SUBMISSION FILE:\")\n",
    "print(f\"  • Location: {OUTPUT_PATH}/submission.csv\")\n",
    "print(f\"  • Records: {submission_final_ensemble.shape[0]}\")\n",
    "print(f\"  • Ready to upload to Kaggle ✓\")\n",
    "\n",
    "print(\"\\n💡 NEXT STEPS FOR FURTHER IMPROVEMENT:\")\n",
    "print(\"  • Tune blend weights using validation set\")\n",
    "print(\"  • Try neural network as base model\")\n",
    "print(\"  • Experiment with different meta-learners (Linear/GradBoost/NN)\")\n",
    "print(\"  • Perform automated hyperparameter search (Optuna/Hyperopt)\")\n",
    "print(\"  • Add more domain-specific features based on domain expertise\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14993753,
     "sourceId": 119082,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31259,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 15.648416,
   "end_time": "2026-01-24T22:08:39.934734",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-24T22:08:24.286318",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
